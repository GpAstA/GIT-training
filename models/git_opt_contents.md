#### GitOPTモデルについて
このリポジトリには、PyTorchで実装されたGitOPTモデルが含まれている。GitOPTモデルは、画像とテキストのデータを統合して処理することができる汎用的なモデルである。このREADMEでは、GitOPTモデルの構造と使用方法について詳述する。

### モデルの概要
GitOPTモデルは、テキストベースのOPTモデルに画像エンコーダを統合し、テキストと画像の両方のデータを処理することができる。モデルは以下のコンポーネントで構成されている：
 - OPTConfig: モデルの設定を定義するクラスである。
 - GitOPTModel: テキストと画像を統合して処理するためのモデルである。
 - GitOPTForCausalLM: 自己回帰型言語モデルとしてのGitOPTモデルである。

### クラスの詳細
## GitOPTConfig
GitOPTConfigはOPTConfigを継承しており、画像エンコーダの設定を追加している。

# メソッド
 - __init__: 初期設定を行う。
 - set_vision_configs: 画像エンコーダの設定を行う。
 - to_dict: 設定を辞書形式に変換する。

## GitOPTModel
GitOPTModelはOPTModelを継承しており、画像エンコーダとテキストエンコーダを統合している。
# 全体の流れのまとめ
 - 1-3: 入力データの検証、シーケンス長とバッチサイズの取得、ヘッドマスクの準備を行う。これにより、モデルが受け取るデータの形式が正しいことを確認し、後続の処理に必要な情報を整える。
 - 4: 画像データをエンコードして視覚特徴量を抽出し、テキスト特徴量と同じ次元に投影する。これにより、画像データとテキストデータを統合する準備を行う。
 - 5: テキストトークンの埋め込みと位置埋め込みを生成し、これを加算する。これにより、入力トークンの位置情報をモデルに提供する。
 - 6: テキストトークンと視覚特徴量を統合し、完全なアテンションマスクを作成する。これにより、統合されたデータに対するアテンションメカニズムを適用できるようにする。
 - 7: 各デコーダレイヤーを順次処理し、最終的な隠れ状態を生成する。必要に応じて、キャッシュやアテンションも返す。これにより、モデルがテキスト生成や予測を行うための最終的な出力を得る。


# メソッド
__init__: モデルの初期化を行う。
 - get_input_embeddings: 入力埋め込み層を取得する。
 - set_input_embeddings: 入力埋め込み層を設定する。
 - _prune_heads: アテンションヘッドを剪定する。
 - _generate_future_mask: 将来のトークンをマスクするためのマスクを生成する。
 - create_attention_mask: アテンションマスクを作成する。
 - forward: フォワードパスを定義する。

## GitOPTForCausalLM
GitOPTForCausalLMはOPTForCausalLMを継承しており、自己回帰型言語モデルとしてGitOPTモデルを使用する。
# 全体のまとめ
GitOPTForCausalLM クラスは、テキスト生成タスクに特化したモデルであり、画像とテキストのデータを統合して処理することができる。以下の機能を提供する：

 - モデルの初期化と重みの設定。
 - 言語モデルの出力層の取得および設定。
 - モデルの入力データを処理してテキスト生成を行い、必要に応じて損失を計算する。
 - 生成用の入力データの準備。
 - ビームサーチなどのデコーディングのためのキャッシュの再整理。


# メソッド
__init__: モデルの初期化を行う。
 - get_output_embeddings: 出力埋め込み層を取得する。
 - set_output_embeddings: 出力埋め込み層を設定する。
 - forward: フォワードパスを定義する。
 - prepare_inputs_for_generation: 生成用の入力を準備する。
 - _reorder_cache: キャッシュを再整理する。