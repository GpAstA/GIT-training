settings:
  model_name: "facebook/opt-125m"  
  vision_model_name: "openai/clip-vit-base-patch16"  
  num_image_with_embedding: 1  
  max_length: 512
  keys_finetune:
    - visual_projection
    - num_image_with_embedding

training:
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  num_train_epochs: 1
  dataloader_num_workers: 15
  fp16: true
  optim: "adamw_torch"
  learning_rate: 5.0e-5
  logging_steps: 100
  evaluation_strategy: "steps"
  save_strategy: "steps"
  eval_steps: 4000
  save_steps: 4000
  save_total_limit: 1
  output_dir: "/home/hata/repo/GIT-training/output"
  deepspeed: "/home/hata/repo/GIT-training/configs/ds_config_zero1.json"
  report_to: "none" 

use_lora: false

lora:
  r: 4
  lora_alpha: 32
  lora_dropout: 0.05
  bias: "none"
  target_modules:
    - "q_proj"
    - "v_proj"

dataset_type:
  - "coco"
  - "vqa-v2"

dataset_save_path: "/home/hata/repo/GIT-training/saved_datasets"
cache_dir: "/home/hata/.cache/huggingface/datasets"
